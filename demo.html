import React, { useState, useEffect, useRef } from 'react';
import { Camera, Mic, MicOff, Volume2, VolumeX, Play, Pause, RotateCcw, Award, Heart, Brain, Smile, Frown, AlertCircle } from 'lucide-react';

const ClassMateAI = () => {
  // Core state management
  const [isActive, setIsActive] = useState(false);
  const [currentLesson, setCurrentLesson] = useState(0);
  const [emotionData, setEmotionData] = useState({
    dominant: 'neutral',
    confidence: 0.8,
    engagement: 0.7,
    frustration: 0.2,
    joy: 0.6
  });
  const [studentProgress, setStudentProgress] = useState({
    correctAnswers: 0,
    totalAttempts: 0,
    currentStreak: 0,
    confidence: 75
  });
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [voiceEnabled, setVoiceEnabled] = useState(true);
  const [currentInstruction, setCurrentInstruction] = useState('');
  const [feedbackMessage, setFeedbackMessage] = useState('');
  const [adaptiveResponse, setAdaptiveResponse] = useState('');
  const [lastSpokenText, setLastSpokenText] = useState('');
  const [studentResponse, setStudentResponse] = useState('');
  const [conversationLog, setConversationLog] = useState([]);

  // Refs for media access
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const speechRecognition = useRef(null);
  const speechSynthesis = useRef(null);

  // Initialize speech recognition and synthesis
  useEffect(() => {
    // Speech Recognition Setup
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      speechRecognition.current = new SpeechRecognition();
      speechRecognition.current.continuous = false;
      speechRecognition.current.interimResults = false;
      speechRecognition.current.lang = 'en-US';

      speechRecognition.current.onstart = () => {
        setIsListening(true);
        addToConversationLog('system', 'Listening...');
      };

      speechRecognition.current.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setStudentResponse(transcript);
        addToConversationLog('student', transcript);
        handleVoiceResponse(transcript);
      };

      speechRecognition.current.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
      };

      speechRecognition.current.onend = () => {
        setIsListening(false);
      };
    }

    // Speech Synthesis Setup
    if ('speechSynthesis' in window) {
      speechSynthesis.current = window.speechSynthesis;
    }

    return () => {
      if (speechRecognition.current) {
        speechRecognition.current.stop();
      }
      if (speechSynthesis.current) {
        speechSynthesis.current.cancel();
      }
    };
  }, []);

  // Add to conversation log
  const addToConversationLog = (speaker, message) => {
    setConversationLog(prev => [...prev, {
      speaker,
      message,
      timestamp: new Date().toLocaleTimeString()
    }]);
  };

  // Text-to-Speech function
  const speakText = (text) => {
    if (!voiceEnabled || !speechSynthesis.current) return;
    
    // Cancel any ongoing speech
    speechSynthesis.current.cancel();
    
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 0.8; // Slightly slower for learning
    utterance.pitch = 1.1; // Slightly higher pitch for friendliness
    utterance.volume = 0.8;
    
    // Try to use a female voice for more engaging experience
    const voices = speechSynthesis.current.getVoices();
    const femaleVoice = voices.find(voice => 
      voice.name.includes('Female') || 
      voice.name.includes('Samantha') || 
      voice.name.includes('Karen') ||
      voice.gender === 'female'
    );
    if (femaleVoice) {
      utterance.voice = femaleVoice;
    }

    utterance.onstart = () => {
      setIsSpeaking(true);
      setLastSpokenText(text);
    };
    
    utterance.onend = () => {
      setIsSpeaking(false);
    };

    speechSynthesis.current.speak(utterance);
    addToConversationLog('ai', text);
  };

  // Start listening for voice input
  const startListening = () => {
    if (speechRecognition.current && !isListening) {
      speechRecognition.current.start();
    }
  };

  // Stop listening
  const stopListening = () => {
    if (speechRecognition.current && isListening) {
      speechRecognition.current.stop();
    }
  };

  // Handle voice responses from student
  const handleVoiceResponse = (transcript) => {
    const currentLessonData = ortonGillinghamLessons[currentLesson];
    const currentWord = currentLessonData.words[currentLessonData.currentWord];
    
    // Simple voice recognition logic for educational responses
    const lowerTranscript = transcript.toLowerCase();
    let isCorrect = false;
    let aiResponse = '';

    if (currentLessonData.type === 'phoneme-identification') {
      // Check if student correctly identifies the sound
      if (lowerTranscript.includes('yes') || lowerTranscript.includes('hear it') || lowerTranscript.includes('a sound')) {
        isCorrect = true;
        aiResponse = `Excellent! You correctly heard the /a/ sound in "${currentWord}". Let's try the next word!`;
      } else if (lowerTranscript.includes('no') || lowerTranscript.includes("don't hear") || lowerTranscript.includes("not there")) {
        isCorrect = false;
        aiResponse = `Let me help you hear it better. Listen carefully: ${currentWord}. The /a/ sound is right in the middle. Try saying it with me: /c/ - /a/ - /t/.`;
      } else {
        aiResponse = `I heard you say "${transcript}". Can you tell me if you hear the /a/ sound in this word? Say "yes I hear it" or "no I don't hear it".`;
      }
    } else if (currentLessonData.type === 'blending') {
      // Check if student correctly reads the word
      if (lowerTranscript.includes(currentWord)) {
        isCorrect = true;
        aiResponse = `Perfect! You read "${currentWord}" correctly! Your blending skills are getting stronger.`;
      } else {
        isCorrect = false;
        aiResponse = `Good try! Let's break it down together. Listen: /c/ - /a/ - /t/. Now blend them smoothly: "cat". Can you try again?`;
      }
    } else if (currentLessonData.type === 'syllable-division') {
      // Check syllable counting
      const syllableCount = currentWord.split(/[aeiou]/g).length - 1; // Simple syllable counting
      if (lowerTranscript.includes('two') && syllableCount === 2) {
        isCorrect = true;
        aiResponse = `Wonderful! "${currentWord}" does have two syllables. You're becoming a syllable expert!`;
      } else if (lowerTranscript.includes('one') || lowerTranscript.includes('three')) {
        isCorrect = false;
        aiResponse = `Let's clap it out together. Listen: "rab-bit". That's two claps, so two syllables!`;
      } else {
        aiResponse = `I heard "${transcript}". Can you clap while saying the word and count the syllables?`;
      }
    }

    // Update progress and provide feedback
    handleStudentResponse(isCorrect);
    
    // Speak the AI response
    setTimeout(() => {
      speakText(aiResponse);
    }, 500);
  };
  const ortonGillinghamLessons = [
    {
      id: 1,
      title: "Letter-Sound Correspondence: 'A'",
      description: "Learning the short 'a' sound with multisensory techniques",
      steps: [
        "Visual: Look at the letter 'a'",
        "Auditory: Listen to the /a/ sound",
        "Kinesthetic: Trace the letter in sand",
        "Practice: Identify /a/ in words"
      ],
      words: ['cat', 'hat', 'bat', 'sat', 'mat'],
      currentWord: 0,
      instruction: "Let's practice the short 'a' sound. I'll show you a word, and you tell me if you hear the /a/ sound.",
      type: 'phoneme-identification'
    },
    {
      id: 2,
      title: "Blending CVC Words",
      description: "Combining consonant-vowel-consonant sounds",
      steps: [
        "Identify each letter sound",
        "Blend sounds slowly",
        "Read the complete word",
        "Use in a sentence"
      ],
      words: ['cat', 'dog', 'run', 'sit', 'big'],
      currentWord: 0,
      instruction: "Now let's blend these sounds together. I'll break down the word, then you read it as one word.",
      type: 'blending'
    },
    {
      id: 3,
      title: "Syllable Division",
      description: "Breaking longer words into manageable parts",
      steps: [
        "Count the vowel sounds",
        "Identify syllable patterns",
        "Divide between consonants",
        "Read each syllable"
      ],
      words: ['rabbit', 'basket', 'sunset', 'winter', 'garden'],
      currentWord: 0,
      instruction: "Let's break this word into smaller parts. How many syllables do you hear?",
      type: 'syllable-division'
    }
  ];

  // Emotion recognition simulation (in real app, this would use camera feed)
  useEffect(() => {
    if (isActive) {
      const interval = setInterval(() => {
        // Simulate emotion detection changes
        const emotions = ['focused', 'frustrated', 'excited', 'confused', 'confident'];
        const randomEmotion = emotions[Math.floor(Math.random() * emotions.length)];
        
        setEmotionData(prev => ({
          dominant: randomEmotion,
          confidence: 0.7 + Math.random() * 0.3,
          engagement: Math.max(0.3, Math.min(0.95, prev.engagement + (Math.random() - 0.5) * 0.2)),
          frustration: Math.max(0, Math.min(0.8, prev.frustration + (Math.random() - 0.5) * 0.3)),
          joy: Math.max(0.2, Math.min(0.9, prev.joy + (Math.random() - 0.5) * 0.25))
        }));
      }, 3000);

      return () => clearInterval(interval);
    }
  }, [isActive]);

  // Adaptive teaching based on emotions
  useEffect(() => {
    let adaptiveMessage = '';
    
    if (emotionData.frustration > 0.6) {
      adaptiveMessage = "I notice you might be feeling frustrated. Let's take a different approach and break this down into smaller steps.";
    } else if (emotionData.engagement < 0.4) {
      adaptiveMessage = "Let's try a more interactive approach! How about we practice with some movement?";
    } else if (emotionData.joy > 0.8) {
      adaptiveMessage = "You're doing fantastic! I can see you're really enjoying this. Let's try something a bit more challenging.";
    } else if (emotionData.dominant === 'confused') {
      adaptiveMessage = "I can see this might be confusing. Let me explain it a different way using a visual example.";
    } else {
      adaptiveMessage = "You're doing great! Let's continue with our lesson.";
    }
    
    setAdaptiveResponse(adaptiveMessage);
    
    // Speak adaptive responses when they change significantly
    if (adaptiveMessage !== adaptiveResponse && voiceEnabled && isActive) {
      setTimeout(() => {
        speakText(adaptiveMessage);
      }, 1000);
    }
  }, [emotionData]);

  // Auto-speak lesson instructions when lesson changes
  useEffect(() => {
    if (isActive && voiceEnabled) {
      const currentLessonData = ortonGillinghamLessons[currentLesson];
      const introMessage = `Let's work on ${currentLessonData.title}. ${currentLessonData.instruction}`;
      setTimeout(() => {
        speakText(introMessage);
      }, 1500);
    }
  }, [currentLesson, isActive]);

  // Start camera and voice session
  const startSession = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { width: 640, height: 480 }, 
        audio: false 
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
      setIsActive(true);
      
      // Welcome message
      setTimeout(() => {
        speakText("Hello! I'm ClassMate AI, your personal learning assistant. I'm here to help you practice reading using special techniques designed just for you. Let's start our lesson!");
      }, 1000);
      
    } catch (error) {
      console.error('Camera access denied:', error);
      // Fallback to demo mode without camera
      setIsActive(true);
      setTimeout(() => {
        speakText("Hello! I'm ClassMate AI. Let's start our lesson together!");
      }, 1000);
    }
  };

  // Stop camera and session
  const stopSession = () => {
    if (videoRef.current && videoRef.current.srcObject) {
      const tracks = videoRef.current.srcObject.getTracks();
      tracks.forEach(track => track.stop());
    }
    if (speechRecognition.current) {
      speechRecognition.current.stop();
    }
    if (speechSynthesis.current) {
      speechSynthesis.current.cancel();
    }
    setIsActive(false);
    setIsListening(false);
    setIsSpeaking(false);
  };

  // Handle student response (for button clicks)
  const handleStudentResponse = (correct) => {
    const newProgress = {
      ...studentProgress,
      totalAttempts: studentProgress.totalAttempts + 1,
      correctAnswers: correct ? studentProgress.correctAnswers + 1 : studentProgress.correctAnswers,
      currentStreak: correct ? studentProgress.currentStreak + 1 : 0
    };
    
    setStudentProgress(newProgress);
    
    if (correct) {
      const encouragingMessages = [
        "Excellent work! You got it right!",
        "Fantastic! You're really getting the hang of this!",
        "Perfect! Your reading skills are improving!",
        "Amazing! You nailed that one!",
        "Wonderful! Keep up the great work!"
      ];
      const message = encouragingMessages[Math.floor(Math.random() * encouragingMessages.length)];
      setFeedbackMessage(message);
      
      // Move to next word or lesson
      const currentLessonData = ortonGillinghamLessons[currentLesson];
      if (currentLessonData.currentWord < currentLessonData.words.length - 1) {
        ortonGillinghamLessons[currentLesson].currentWord++;
        // Announce next word
        setTimeout(() => {
          const nextWord = currentLessonData.words[currentLessonData.currentWord];
          speakText(`Great! Now let's try the word "${nextWord}"`);
        }, 2000);
      } else {
        setTimeout(() => {
          speakText("Congratulations! You've completed this lesson. You're doing amazing!");
        }, 2000);
      }
    } else {
      const supportiveMessages = [
        "Not quite, but that's okay! Let's try again with some help.",
        "Good try! Let me help you work through this step by step.",
        "That's alright! Learning takes practice. Let's break it down together.",
        "No worries! Everyone learns at their own pace. Let's try a different approach."
      ];
      const message = supportiveMessages[Math.floor(Math.random() * supportiveMessages.length)];
      setFeedbackMessage(message);
    }
  };

  // Current lesson data
  const currentLessonData = ortonGillinghamLessons[currentLesson];
  const currentWord = currentLessonData.words[currentLessonData.currentWord];

  // Emotion color coding
  const getEmotionColor = (emotion) => {
    const colors = {
      focused: 'text-green-600',
      frustrated: 'text-red-600',
      excited: 'text-yellow-600',
      confused: 'text-orange-600',
      confident: 'text-blue-600',
      neutral: 'text-gray-600'
    };
    return colors[emotion] || 'text-gray-600';
  };

  const getEmotionIcon = (emotion) => {
    const icons = {
      focused: Brain,
      frustrated: Frown,
      excited: Smile,
      confused: AlertCircle,
      confident: Award,
      neutral: Heart
    };
    const Icon = icons[emotion] || Heart;
    return <Icon className="w-5 h-5" />;
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 to-purple-50 p-4">
      <div className="max-w-7xl mx-auto">
        {/* Header */}
        <div className="bg-white rounded-lg shadow-lg p-6 mb-6">
          <div className="flex items-center justify-between">
            <div>
              <h1 className="text-3xl font-bold text-gray-800 mb-2">
                ClassMate AI - Orton-Gillingham Assistant
              </h1>
              <p className="text-gray-600">
                Personalized dyslexia instruction with real-time emotion recognition
              </p>
            </div>
            <div className="flex gap-3">
              {!isActive ? (
                <button
                  onClick={startSession}
                  className="bg-green-600 hover:bg-green-700 text-white px-6 py-3 rounded-lg flex items-center gap-2 font-semibold transition-colors"
                >
                  <Play className="w-5 h-5" />
                  Start Voice Session
                </button>
              ) : (
                <>
                  <button
                    onClick={() => setVoiceEnabled(!voiceEnabled)}
                    className={`px-6 py-3 rounded-lg flex items-center gap-2 font-semibold transition-colors ${
                      voiceEnabled 
                        ? 'bg-blue-600 hover:bg-blue-700 text-white' 
                        : 'bg-gray-600 hover:bg-gray-700 text-white'
                    }`}
                  >
                    {voiceEnabled ? <Volume2 className="w-5 h-5" /> : <VolumeX className="w-5 h-5" />}
                    Voice {voiceEnabled ? 'On' : 'Off'}
                  </button>
                  <button
                    onClick={stopSession}
                    className="bg-red-600 hover:bg-red-700 text-white px-6 py-3 rounded-lg flex items-center gap-2 font-semibold transition-colors"
                  >
                    <Pause className="w-5 h-5" />
                    End Session
                  </button>
                </>
              )}
            </div>
          </div>
        </div>

        {isActive && (
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
            {/* Left Column - Emotion Recognition */}
            <div className="space-y-6">
              {/* Camera Feed */}
              <div className="bg-white rounded-lg shadow-lg p-6">
                <h3 className="text-lg font-semibold mb-4 flex items-center gap-2">
                  <Camera className="w-5 h-5" />
                  Emotion Recognition
                </h3>
                <div className="relative">
                  <video
                    ref={videoRef}
                    autoPlay
                    muted
                    className="w-full rounded-lg bg-gray-200"
                    style={{ height: '200px', objectFit: 'cover' }}
                  />
                  <div className="absolute top-2 right-2 bg-black bg-opacity-50 text-white px-2 py-1 rounded text-sm">
                    Live Feed
                  </div>
                </div>
              </div>

              {/* Emotion Data */}
              <div className="bg-white rounded-lg shadow-lg p-6">
                <h3 className="text-lg font-semibold mb-4">Current Emotional State</h3>
                <div className="space-y-3">
                  <div className="flex items-center justify-between">
                    <div className={`flex items-center gap-2 ${getEmotionColor(emotionData.dominant)}`}>
                      {getEmotionIcon(emotionData.dominant)}
                      <span className="font-medium capitalize">{emotionData.dominant}</span>
                    </div>
                    <span className="text-sm text-gray-500">
                      {Math.round(emotionData.confidence * 100)}% confident
                    </span>
                  </div>
                  
                  <div className="space-y-2">
                    <div className="flex justify-between text-sm">
                      <span>Engagement</span>
                      <span>{Math.round(emotionData.engagement * 100)}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2">
                      <div 
                        className="bg-green-600 h-2 rounded-full transition-all"
                        style={{ width: `${emotionData.engagement * 100}%` }}
                      />
                    </div>
                  </div>

                  <div className="space-y-2">
                    <div className="flex justify-between text-sm">
                      <span>Frustration</span>
                      <span>{Math.round(emotionData.frustration * 100)}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2">
                      <div 
                        className="bg-red-600 h-2 rounded-full transition-all"
                        style={{ width: `${emotionData.frustration * 100}%` }}
                      />
                    </div>
                  </div>

                  <div className="space-y-2">
                    <div className="flex justify-between text-sm">
                      <span>Joy</span>
                      <span>{Math.round(emotionData.joy * 100)}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2">
                      <div 
                        className="bg-yellow-500 h-2 rounded-full transition-all"
                        style={{ width: `${emotionData.joy * 100}%` }}
                      />
                    </div>
                  </div>
                </div>
              </div>

              {/* Progress Tracking */}
              <div className="bg-white rounded-lg shadow-lg p-6">
                <h3 className="text-lg font-semibold mb-4 flex items-center gap-2">
                  <Award className="w-5 h-5" />
                  Progress
                </h3>
                <div className="space-y-3">
                  <div className="flex justify-between">
                    <span>Correct Answers</span>
                    <span className="font-semibold text-green-600">
                      {studentProgress.correctAnswers}/{studentProgress.totalAttempts}
                    </span>
                  </div>
                  <div className="flex justify-between">
                    <span>Current Streak</span>
                    <span className="font-semibold text-blue-600">
                      {studentProgress.currentStreak}
                    </span>
                  </div>
                  <div className="space-y-2">
                    <div className="flex justify-between text-sm">
                      <span>Confidence Level</span>
                      <span>{studentProgress.confidence}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2">
                      <div 
                        className="bg-blue-600 h-2 rounded-full"
                        style={{ width: `${studentProgress.confidence}%` }}
                      />
                    </div>
                  </div>
                </div>
              </div>

              {/* Voice Controls */}
              <div className="bg-white rounded-lg shadow-lg p-6">
                <h3 className="text-lg font-semibold mb-4 flex items-center gap-2">
                  <Mic className="w-5 h-5" />
                  Voice Interaction
                </h3>
                <div className="space-y-4">
                  <div className="flex gap-2">
                    <button
                      onClick={startListening}
                      disabled={isListening || !voiceEnabled}
                      className={`flex-1 py-2 px-4 rounded-lg font-semibold transition-colors ${
                        isListening 
                          ? 'bg-red-600 text-white' 
                          : voiceEnabled
                            ? 'bg-green-600 hover:bg-green-700 text-white'
                            : 'bg-gray-400 text-gray-600 cursor-not-allowed'
                      }`}
                    >
                      <Mic className="w-4 h-4 inline mr-2" />
                      {isListening ? 'Listening...' : 'Start Talking'}
                    </button>
                  </div>
                  
                  {isSpeaking && (
                    <div className="bg-blue-100 p-3 rounded-lg">
                      <div className="flex items-center gap-2 text-blue-800">
                        <Volume2 className="w-4 h-4" />
                        <span className="text-sm font-medium">AI Speaking...</span>
                      </div>
                      <p className="text-sm text-blue-700 mt-1">{lastSpokenText}</p>
                    </div>
                  )}
                  
                  {studentResponse && (
                    <div className="bg-green-100 p-3 rounded-lg">
                      <div className="text-green-800 text-sm font-medium">You said:</div>
                      <p className="text-green-700">{studentResponse}</p>
                    </div>
                  )}
                </div>
              </div>

              {/* Conversation Log */}
              <div className="bg-white rounded-lg shadow-lg p-6">
                <h3 className="text-lg font-semibold mb-4">Conversation</h3>
                <div className="max-h-60 overflow-y-auto space-y-2">
                  {conversationLog.slice(-6).map((entry, index) => (
                    <div key={index} className={`p-2 rounded text-sm ${
                      entry.speaker === 'ai' ? 'bg-blue-100 text-blue-800' :
                      entry.speaker === 'student' ? 'bg-green-100 text-green-800' :
                      'bg-gray-100 text-gray-600'
                    }`}>
                      <div className="font-semibold capitalize">{entry.speaker}:</div>
                      <div>{entry.message}</div>
                    </div>
                  ))}
                </div>
              </div>
            </div>

            {/* Center Column - Main Lesson */}
            <div className="lg:col-span-2 space-y-6">
              {/* Adaptive Response */}
              {adaptiveResponse && (
                <div className="bg-blue-100 border-l-4 border-blue-500 p-4 rounded-r-lg">
                  <div className="flex items-center gap-2 mb-2">
                    <Brain className="w-5 h-5 text-blue-600" />
                    <span className="font-semibold text-blue-800">AI Adaptation</span>
                  </div>
                  <p className="text-blue-700">{adaptiveResponse}</p>
                </div>
              )}

              {/* Current Lesson */}
              <div className="bg-white rounded-lg shadow-lg p-6">
                <div className="flex items-center justify-between mb-4">
                  <h2 className="text-xl font-semibold">{currentLessonData.title}</h2>
                  <div className="text-sm text-gray-500">
                    Lesson {currentLesson + 1} of {ortonGillinghamLessons.length}
                  </div>
                </div>
                
                <p className="text-gray-600 mb-6">{currentLessonData.description}</p>

                {/* Multisensory Learning Steps */}
                <div className="mb-6">
                  <h3 className="font-semibold mb-3">Orton-Gillingham Steps:</h3>
                  <div className="grid grid-cols-2 gap-3">
                    {currentLessonData.steps.map((step, index) => (
                      <div key={index} className="bg-gray-50 p-3 rounded-lg">
                        <div className="flex items-center gap-2">
                          <div className="w-6 h-6 bg-blue-600 text-white rounded-full flex items-center justify-center text-sm font-semibold">
                            {index + 1}
                          </div>
                          <span className="text-sm">{step}</span>
                        </div>
                      </div>
                    ))}
                  </div>
                </div>

                {/* Current Word Practice */}
                <div className="bg-gradient-to-r from-purple-100 to-blue-100 p-6 rounded-lg">
                  <h3 className="text-lg font-semibold mb-3">Current Practice</h3>
                  <p className="text-gray-700 mb-4">{currentLessonData.instruction}</p>
                  
                  <div className="text-center mb-6">
                    <div className="inline-block bg-white p-8 rounded-lg shadow-lg">
                      <span className="text-4xl font-bold text-gray-800 tracking-wider">
                        {currentWord}
                      </span>
                    </div>
                  </div>

                  {/* Interactive Buttons */}
                  <div className="flex flex-col gap-4">
                    <div className="text-center">
                      <button
                        onClick={startListening}
                        disabled={isListening || !voiceEnabled}
                        className={`px-8 py-4 rounded-lg font-semibold transition-all text-lg ${
                          isListening 
                            ? 'bg-red-600 text-white animate-pulse' 
                            : voiceEnabled
                              ? 'bg-purple-600 hover:bg-purple-700 text-white shadow-lg'
                              : 'bg-gray-400 text-gray-600 cursor-not-allowed'
                        }`}
                      >
                        <Mic className="w-6 h-6 inline mr-2" />
                        {isListening ? 'Listening...' : 'Click to Speak Your Answer'}
                      </button>
                    </div>
                    
                    <div className="text-center text-gray-500">or</div>
                    
                    <div className="flex justify-center gap-4">
                      <button
                        onClick={() => handleStudentResponse(true)}
                        className="bg-green-600 hover:bg-green-700 text-white px-6 py-2 rounded-lg font-semibold transition-colors"
                      >
                        ✓ I hear the sound!
                      </button>
                      <button
                        onClick={() => handleStudentResponse(false)}
                        className="bg-red-600 hover:bg-red-700 text-white px-6 py-2 rounded-lg font-semibold transition-colors"
                      >
                        ✗ I don't hear it
                      </button>
                    </div>
                  </div>
                </div>

                {/* Feedback */}
                {feedbackMessage && (
                  <div className="mt-4 p-4 bg-yellow-100 border-l-4 border-yellow-500 rounded-r-lg">
                    <p className="text-yellow-800 font-medium">{feedbackMessage}</p>
                  </div>
                )}

                {/* Word Progress */}
                <div className="mt-6">
                  <div className="flex justify-between text-sm text-gray-600 mb-2">
                    <span>Word Progress</span>
                    <span>{currentLessonData.currentWord + 1} of {currentLessonData.words.length}</span>
                  </div>
                  <div className="w-full bg-gray-200 rounded-full h-2">
                    <div 
                      className="bg-purple-600 h-2 rounded-full transition-all"
                      style={{ width: `${((currentLessonData.currentWord + 1) / currentLessonData.words.length) * 100}%` }}
                    />
                  </div>
                </div>
              </div>

              {/* Lesson Navigation */}
              <div className="bg-white rounded-lg shadow-lg p-6">
                <h3 className="text-lg font-semibold mb-4">Available Lessons</h3>
                <div className="grid grid-cols-1 md:grid-cols-3 gap-3">
                  {ortonGillinghamLessons.map((lesson, index) => (
                    <button
                      key={lesson.id}
                      onClick={() => setCurrentLesson(index)}
                      className={`p-3 rounded-lg text-left transition-colors ${
                        currentLesson === index
                          ? 'bg-blue-600 text-white'
                          : 'bg-gray-100 hover:bg-gray-200 text-gray-700'
                      }`}
                    >
                      <div className="font-semibold text-sm">{lesson.title}</div>
                      <div className="text-xs opacity-75 mt-1">{lesson.type}</div>
                    </button>
                  ))}
                </div>
              </div>
            </div>
          </div>
        )}

        {!isActive && (
          <div className="bg-white rounded-lg shadow-lg p-8 text-center">
            <Brain className="w-16 h-16 text-blue-600 mx-auto mb-4" />
            <h2 className="text-2xl font-semibold mb-4">Welcome to ClassMate AI</h2>
            <p className="text-gray-600 mb-6 max-w-2xl mx-auto">
              This prototype demonstrates how AI can provide personalized Orton-Gillingham instruction 
              while adapting to student emotions in real-time. Click "Start Session" to begin the demo.
            </p>
            <div className="grid grid-cols-1 md:grid-cols-3 gap-4 max-w-3xl mx-auto text-sm">
              <div className="bg-blue-50 p-4 rounded-lg">
                <Camera className="w-8 h-8 text-blue-600 mx-auto mb-2" />
                <h3 className="font-semibold">Emotion Recognition</h3>
                <p className="text-gray-600">Real-time facial emotion detection</p>
              </div>
              <div className="bg-green-50 p-4 rounded-lg">
                <Brain className="w-8 h-8 text-green-600 mx-auto mb-2" />
                <h3 className="font-semibold">Orton-Gillingham</h3>
                <p className="text-gray-600">Evidence-based dyslexia instruction</p>
              </div>
              <div className="bg-purple-50 p-4 rounded-lg">
                <Heart className="w-8 h-8 text-purple-600 mx-auto mb-2" />
                <h3 className="font-semibold">Adaptive Learning</h3>
                <p className="text-gray-600">Instruction adapts to emotional state</p>
              </div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

